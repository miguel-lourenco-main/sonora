import { Tables } from "./database.types";

export interface Choice {
  text: string;
  nextNodeId: string;
}

/**
 * A StoryNode always has either choices or a nextNodeId
 */
export type WordTiming = {
  word: string;
  start: number;
  end: number;
};

export type BaseContentNode = {
  id: string;
  text: string;
  choices?: Choice[];
  nextNodeId?: string;
  audioUrl?: string;
};

export type OpenAIContentNode = BaseContentNode & {
  voiceId: 'default';
};

export type ElevenLabsContentNode = BaseContentNode & {
  voiceId: string;
  wordTimings?: WordTiming[];
};

export type ContentNode = OpenAIContentNode | ElevenLabsContentNode;

export interface Content {
  initialNodeId: string;
  nodes: Record<string, ContentNode>;
}

export interface Chapter {
  number: number;
  title: string;
  content: Content;
}

export interface Story {
  id: string;
  title: string;
  author: string;
  label: string;
  coverUrl: string;
  chapters: Chapter[];
  currentChapter: number;
  totalChapters: number;
}

export interface Audiobook {
  id: string;
  title: string;
  author: string;
  coverUrl: string;
  duration: string;
  narrator: string;
  category: string;
}

// These are the types that map the narration files generated by the generate-audio.ts script
export interface Subtitle {
  start: number;
  end: number;
  text: string;
}

export interface SubtitleFile {
  subtitles: Subtitle[];
}

export interface NodeChunk {
  start: number;
  end: number;
  text: string;
}

export interface NodeDuration {
  duration: number;
  startTimestamp: number;
  chunks: Subtitle[];
}

export interface DurationMetadata {
  totalDuration: number;
  nodes: Record<string, NodeDuration>;
}

export interface HistoryItem {
  nodeId: string;
}

export interface AudioDeviceConfig {
  channelCount: number;
  sampleRate: number;
  sampleSize: number;
  echoCancellation: boolean;
  noiseSuppression: boolean;
}

export type Voice = Tables<'voice'>;

export type Alignment = {
  characters: string[];
  character_start_times_seconds: number[];
  character_end_times_seconds: number[];
};

export type ElevenLabsTextToSpeechResponse = {
  audio_base64: string;
  alignment: Alignment;
};

export type OpenAISpeechResponse = {
  audioUrl: string;
  text: string;
  provider: 'openai';
};

export type ElevenLabsSpeechResponse = {
  audioUrl: string;
  wordTimings: WordTiming[];
  provider: 'elevenlabs';
};

export type SpeechResponse = OpenAISpeechResponse | ElevenLabsSpeechResponse;